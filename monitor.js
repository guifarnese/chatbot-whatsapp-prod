const axios = require('axios');
const fs = require('fs');
const path = require('path');

// ConfiguraÃ§Ãµes
const HEALTH_CHECK_URL = process.env.HEALTH_CHECK_URL || 'http://localhost:3000/health';
const CHECK_INTERVAL = 30000; // 30 segundos
const MAX_RETRIES = 3;
const LOG_FILE = path.join(__dirname, 'monitor.log');

// FunÃ§Ã£o para log
function log(message) {
  const timestamp = new Date().toISOString();
  const logMessage = `[${timestamp}] ${message}\n`;
  console.log(logMessage.trim());
  fs.appendFileSync(LOG_FILE, logMessage);
}

// FunÃ§Ã£o para verificar saÃºde da aplicaÃ§Ã£o
async function checkHealth() {
  try {
    const response = await axios.get(HEALTH_CHECK_URL, { timeout: 10000 });
    if (response.status === 200 && response.data.status === 'ok') {
      log('âœ… Health check OK');
      return true;
    } else {
      log('âŒ Health check failed - Invalid response');
      return false;
    }
  } catch (error) {
    log(`âŒ Health check failed - ${error.message}`);
    return false;
  }
}

// FunÃ§Ã£o para reiniciar aplicaÃ§Ã£o (se necessÃ¡rio)
async function restartApplication() {
  log('ðŸ”„ Attempting to restart application...');
  // Em ambiente de produÃ§Ã£o, o Railway/Render farÃ¡ o restart automÃ¡tico
  // Este Ã© apenas um placeholder para logs
  process.exit(1); // ForÃ§a restart do container
}

// Monitor principal
let consecutiveFailures = 0;

async function monitor() {
  const isHealthy = await checkHealth();
  
  if (isHealthy) {
    consecutiveFailures = 0;
  } else {
    consecutiveFailures++;
    log(`âš ï¸ Consecutive failures: ${consecutiveFailures}/${MAX_RETRIES}`);
    
    if (consecutiveFailures >= MAX_RETRIES) {
      log('ðŸš¨ Max retries reached, attempting restart...');
      await restartApplication();
    }
  }
}

// Iniciar monitoramento
log('ðŸš€ Starting health monitor...');
setInterval(monitor, CHECK_INTERVAL);

// VerificaÃ§Ã£o inicial
monitor();
